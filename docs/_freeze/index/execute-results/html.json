{
  "hash": "433b8fd3fc1a6898b70a0a052490b5a2",
  "result": {
    "markdown": "## Why developing models for mobile devices\n\n- Develop mechanical sympathy and understand the real use cases\n\n- Crowd-source training data, e.g. image recognition\n\n## How to integrate transformers into mobile devices\n\nDepending on where the model is:\n\n- [server-based]{.yellow}: model is located on an enterprise server\n\n- [client-based]{.yellow}: model is built into the user's device\n\n\n## Demo: server-based GPT3 chatbot\n\n:::: {.columns}\n::: {.column width='30%'}\n\n![](./images/gpt3.png){height=\"600px\"}\n:::\n::: {.column width='60%'}\n\n![](./images/server.png)\n\n:::\n::::\n\n## Making API requests\n\n[Python API Server]{.yellow}\n\n```{.python filename='server.py' code-line-numbers=\"|2-3|15-16|19-20\"}\nimport openai\ndef reply(prompt: str):\n     response = openai.Completion.create(\n        model=\"text-davinci-002\",\n        prompt=prompt,\n        temperature=0.3,\n        max_tokens=60,\n        top_p=1.0,\n        frequency_penalty=0.5,\n        presence_penalty=0.0,\n        stop=[\"You:\"],\n    )\n    return response[\"choices\"][0][\"text\"].strip()\n\n@app.post(\"/chat\")\ndef gpt3_reply(prompt: str):\n    all_messages = get_all_messages()\n    prompt = \"\\n\".join(all_messages)\n    reply = reply(prompt)\n    return {\"text\": reply}\n```\n\n[IOS app]{.yellow}\n\n```{.swift filename=\"client.swift\"}\nAF.request(\"http://localhost:8000/chat\", method: .post).responseData { response in\n    add_message(response.text)\n}\n```\n\n## Pros & Cons of the client-server approach\n\n[Pros]{.yellow}\n\n- Easy to implement and reason about, built-in support on many platforms (e.g. [huggingface](https://huggingface.co/inference-api), [replicate](https://replicate.com/docs/reference/http))\n\n- Universal to any language, frameworks and models\n\n\n[Cons]{.yellow}\n\n- Limited usage in areas with insuffcient international bandwidth\n\n- Additional codebase, infrastructure, and maintenance\n\n## Alternative: built-in model in the client\n\nApple provids the [[Core ML]{.yellow}](https://developer.apple.com/documentation/coreml) framework for transforming common machine learning models into a `.mlmodel` format that can be built directly into an IOS app's bundle.\n\n![](https://files.readme.io/d2229ff-core-ml-tools-front-page.png)\n\n\n## Transforming BERT into `.mlmodel`\n\n\n```{.python filename=\"transform-bert.py\" code-line-numbers=\"|1|6-9|16-17\"}\nimport coremltools as ct\nimport numpy as np\nimport tensorflow as tf\nfrom transformers import DistilBertTokenizer, TFDistilBertForMaskedLM\n\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\ndistilbert_model = TFDistilBertForMaskedLM.from_pretrained(\n    \"distilbert-base-uncased-distilled-squad\"\n)\n\ninput_shape = (1, 20)\ninput_layer = tf.keras.layers.Input(shape=input_shape[1:], dtype=tf.int32, name=\"input\")\nprediction_model = distilbert_model(input_layer)\ntf_model = tf.keras.models.Model(inputs=input_layer, outputs=prediction_model)\n\nmlmodel = ct.convert(tf_model)\nmlmodel.save(\"distilbert.mlmodel\")\n```\n\n::: {.fragment .fade-up}\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/bert.png){width=126}\n:::\n:::\n\n:::\n\n## Demo: client-based Q&A system using BERT\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/QA.png){fig-align='center' width=590}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}